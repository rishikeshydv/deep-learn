{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple RL-based attention mechanism\n",
    "class RLAttention(nn.Module):\n",
    "    def __init__(self, model_dimension, n_heads):\n",
    "        super(RLAttention, self).__init__()\n",
    "        self.model_dimension = model_dimension\n",
    "        self.n_heads = n_heads\n",
    "        self.dimension = model_dimension // n_heads\n",
    "\n",
    "        # Linear layers for Q, K, V, and output\n",
    "        self.q = nn.Linear(model_dimension, model_dimension)\n",
    "        self.k = nn.Linear(model_dimension, model_dimension)\n",
    "        self.v = nn.Linear(model_dimension, model_dimension)\n",
    "        self.o = nn.Linear(model_dimension, model_dimension)\n",
    "\n",
    "        # Define the policy network (for selecting keys based on queries)\n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(self.dimension, 64),  # Input is the Query dimension\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, self.dimension),  # Output is the action (selection of relevant keys)\n",
    "            nn.Softmax(dim=-1)  # Probability distribution over keys\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Split the input tensors into multi-head dimensions\n",
    "        Q = self.split_heads(self.q(Q))\n",
    "        K = self.split_heads(self.k(K))\n",
    "        V = self.split_heads(self.v(V))\n",
    "        \n",
    "        # Calculate attention weights using RL policy\n",
    "        attention_weights = self.select_attention_weights(Q, K, mask)\n",
    "        # Apply the attention weights to the values\n",
    "        attention_weights = attention_weights.transpose(-2, -1)\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        combined = self.combine_heads(output)\n",
    "        return self.o(combined)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, model_dim = x.size()\n",
    "        x = x.view(batch_size, seq_length, self.n_heads, self.dimension)\n",
    "        return x.permute(0, 2, 1, 3)  # (batch_size, n_heads, seq_length, dimension)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, n_heads, seq_length, dimension = x.size()\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        return x.view(batch_size, seq_length, n_heads * dimension)\n",
    "\n",
    "    def select_attention_weights(self, Q, K, mask=None):\n",
    "        # Assume Q and K are (batch_size, n_heads, seq_length, dimension)\n",
    "        batch_size, n_heads, seq_length, dimension = Q.size()\n",
    "\n",
    "        # Flatten the queries for policy input\n",
    "        Q_flat = Q.reshape(batch_size * n_heads * seq_length, dimension)\n",
    "        \n",
    "        # Use the policy network to decide the attention weights for each query\n",
    "        action_probs = self.policy_network(Q_flat)\n",
    "        \n",
    "        # Reshape action_probs back to attention shape\n",
    "        action_probs = action_probs.view(batch_size, n_heads, seq_length, seq_length)\n",
    "\n",
    "        # Apply softmax along the last dimension for attention\n",
    "        attention_weights = torch.softmax(action_probs, dim=-1)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).unsqueeze(2)  # Adjust mask shape for multi-head attention\n",
    "            attention_weights = attention_weights.masked_fill(mask == 0, float('-inf'))\n",
    "            attention_weights = torch.softmax(attention_weights, dim=-1)\n",
    "\n",
    "        return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#datasets \n",
    "src_vocab = {\"<pad>\": 0, \"<eos>\": 1, \"<unk>\": 2, \"How\": 3, \"are\": 4, \"you\": 5, \"?\": 6}\n",
    "tgt_vocab = {\"<pad>\": 0, \"<eos>\": 1, \"<unk>\": 2, \"Comment\": 3, \"allez-vous\": 4, \"?\": 5}\n",
    "\n",
    "\n",
    "src_sentence = [\"How\", \"are\", \"you\", \"?\"]\n",
    "tgt_sentence = [\"Comment\", \"allez-vous\", \"?\"]\n",
    "\n",
    "src_indices = [src_vocab[word] for word in src_sentence]\n",
    "tgt_indices = [tgt_vocab[word] for word in tgt_sentence]\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "embedding_dim = 64\n",
    "\n",
    "src_embedding = nn.Embedding(src_vocab_size, embedding_dim)\n",
    "tgt_embedding = nn.Embedding(tgt_vocab_size, embedding_dim)\n",
    "\n",
    "\n",
    "# Convert indices to tensors\n",
    "src_indices_tensor = torch.tensor([src_indices], dtype=torch.long)  # Shape: (batch_size, seq_length)\n",
    "tgt_indices_tensor = torch.tensor([tgt_indices], dtype=torch.long)  # Shape: (batch_size, seq_length)\n",
    "\n",
    "# Generate masks (1 for valid tokens, 0 for padding)\n",
    "src_mask = (src_indices_tensor != src_vocab[\"<pad>\"])\n",
    "tgt_mask = (tgt_indices_tensor != tgt_vocab[\"<pad>\"])\n",
    "\n",
    "# Get embeddings\n",
    "src_embeddings = src_embedding(src_indices_tensor)  # Shape: (batch_size, seq_length, embedding_dim)\n",
    "tgt_embeddings = tgt_embedding(tgt_indices_tensor)  # Shape: (batch_size, seq_length, embedding_dim)\n",
    "\n",
    "Q = src_embeddings  # Source sentence embeddings\n",
    "K = tgt_embeddings  # Target sentence embeddings (keys)\n",
    "V = tgt_embeddings  # Target sentence embeddings (values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 8, 4, 4]' is invalid for input of size 256",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttention output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape) \n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m, in \u001b[0;36mRLAttention.forward\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_heads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv(V))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Calculate attention weights using RL policy\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_attention_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Apply the attention weights to the values\u001b[39;00m\n\u001b[1;32m     33\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m attention_weights\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m, in \u001b[0;36mRLAttention.select_attention_weights\u001b[0;34m(self, Q, K, mask)\u001b[0m\n\u001b[1;32m     57\u001b[0m action_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_network(Q_flat)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Reshape action_probs back to attention shape\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m action_probs \u001b[38;5;241m=\u001b[39m \u001b[43maction_probs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Apply softmax along the last dimension for attention\u001b[39;00m\n\u001b[1;32m     63\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(action_probs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 8, 4, 4]' is invalid for input of size 256"
     ]
    }
   ],
   "source": [
    "# Create the model, define optimizer and loss function\n",
    "model = RLAttention(model_dimension=64, n_heads=8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Forward pass\n",
    "output = model(Q, K, V, mask=tgt_mask)\n",
    "\n",
    "print(\"Attention output shape:\", output.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reward function (this is a simple placeholder; a real reward function should be based on the task)\n",
    "def reward_function(predicted_translation, target_translation):\n",
    "    # Compute reward as cosine similarity between predicted and target translation (simplified)\n",
    "    return torch.cosine_similarity(predicted_translation, target_translation, dim=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (8x32 and 8x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttention output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Define the reward function (this is a simple placeholder; a real reward function should be based on the task)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[117], line 37\u001b[0m, in \u001b[0;36mRLAttention.forward\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     35\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(Q, K):\n\u001b[0;32m---> 37\u001b[0m     action_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Flatten q for policy input\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     action_probs \u001b[38;5;241m=\u001b[39m action_probs\u001b[38;5;241m.\u001b[39mview(q\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), q\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), q\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# Reshape to (batch_size, seq_length, seq_length)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     attention_weights\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39msoftmax(action_probs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (8x32 and 8x64)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Define a simple RL-based attention mechanism\n",
    "class RLAttention(nn.Module):\n",
    "    def __init__(self, model_dimension, n_heads):\n",
    "        super(RLAttention, self).__init__()\n",
    "        self.model_dimension = model_dimension\n",
    "        self.n_heads = n_heads\n",
    "        self.dimension = model_dimension // n_heads  # Ensure this is an integer\n",
    "        \n",
    "        # Linear layers for Q, K, V, and output\n",
    "        self.q = nn.Linear(model_dimension, model_dimension)\n",
    "        self.k = nn.Linear(model_dimension, model_dimension)\n",
    "        self.v = nn.Linear(model_dimension, model_dimension)\n",
    "        self.o = nn.Linear(model_dimension, model_dimension)\n",
    "\n",
    "        # Define the policy network (for selecting keys based on queries)\n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(self.dimension, 64),  # Input is the Query dimension\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, self.dimension),  # Output is the action (selection of relevant keys)\n",
    "            nn.Softmax(dim=-1)  # Probability distribution over keys\n",
    "        )\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Split the input tensors into multi-head dimensions\n",
    "        Q = self.split_heads(self.q(Q))  # Shape: (batch_size, n_heads, seq_length, dimension)\n",
    "        K = self.split_heads(self.k(K))  # Shape: (batch_size, n_heads, seq_length, dimension)\n",
    "        V = self.split_heads(self.v(V))  # Shape: (batch_size, n_heads, seq_length, dimension)\n",
    "\n",
    "        # Calculate attention weights using RL policy\n",
    "        attention_weights = []\n",
    "        for q, k in zip(Q, K):\n",
    "            action_probs = self.policy_network(q.reshape(q.size(0), -1))  # Flatten q for policy input\n",
    "            action_probs = action_probs.view(q.size(0), q.size(1), q.size(2))  # Reshape to (batch_size, seq_length, seq_length)\n",
    "            attention_weights.append(torch.softmax(action_probs, dim=-1))\n",
    "\n",
    "        attention_weights = torch.cat(attention_weights, dim=1)  # Shape: (batch_size, n_heads, seq_length, seq_length)\n",
    "\n",
    "        # Apply attention weights to the values (V)\n",
    "        output = torch.matmul(attention_weights, V.transpose(2, 3))  # Transpose V to align dimensions\n",
    "        output = output.transpose(2, 3)  # (batch_size, n_heads, seq_length, dimension)\n",
    "\n",
    "        combined = self.combine_heads(output)  # Combine heads back\n",
    "        return self.o(combined)  # Output of the attention layer\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, model_dim = x.size()\n",
    "        x = x.view(batch_size, seq_length, self.n_heads, self.dimension)  # Split into heads\n",
    "        return x.permute(0, 2, 1, 3)  # (batch_size, n_heads, seq_length, dimension)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, n_heads, seq_length, dimension = x.size()\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  # Re-order dimensions\n",
    "        return x.view(batch_size, seq_length, n_heads * dimension)  # Combine heads\n",
    "\n",
    "\n",
    "# datasets \n",
    "src_vocab = {\"<pad>\": 0, \"<eos>\": 1, \"<unk>\": 2, \"How\": 3, \"are\": 4, \"you\": 5, \"?\": 6}\n",
    "tgt_vocab = {\"<pad>\": 0, \"<eos>\": 1, \"<unk>\": 2, \"Comment\": 3, \"allez-vous\": 4, \"?\": 5}\n",
    "\n",
    "src_sentence = [\"How\", \"are\", \"you\", \"?\"]\n",
    "tgt_sentence = [\"Comment\", \"allez-vous\", \"?\"]\n",
    "\n",
    "src_indices = [src_vocab[word] for word in src_sentence]\n",
    "tgt_indices = [tgt_vocab[word] for word in tgt_sentence]\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "embedding_dim = 64\n",
    "\n",
    "src_embedding = nn.Embedding(src_vocab_size, embedding_dim)\n",
    "tgt_embedding = nn.Embedding(tgt_vocab_size, embedding_dim)\n",
    "\n",
    "# Convert indices to tensors\n",
    "src_indices_tensor = torch.tensor([src_indices], dtype=torch.long)  # Shape: (batch_size, seq_length)\n",
    "tgt_indices_tensor = torch.tensor([tgt_indices], dtype=torch.long)  # Shape: (batch_size, seq_length)\n",
    "\n",
    "# Generate masks (1 for valid tokens, 0 for padding)\n",
    "src_mask = (src_indices_tensor != src_vocab[\"<pad>\"])\n",
    "tgt_mask = (tgt_indices_tensor != tgt_vocab[\"<pad>\"])\n",
    "\n",
    "# Get embeddings\n",
    "src_embeddings = src_embedding(src_indices_tensor)  # Shape: (batch_size, seq_length, embedding_dim)\n",
    "tgt_embeddings = tgt_embedding(tgt_indices_tensor)  # Shape: (batch_size, seq_length, embedding_dim)\n",
    "\n",
    "Q = src_embeddings  # Source sentence embeddings\n",
    "K = tgt_embeddings  # Target sentence embeddings (keys)\n",
    "V = tgt_embeddings  # Target sentence embeddings (values)\n",
    "\n",
    "# Create the model, define optimizer and loss function\n",
    "model = RLAttention(model_dimension=64, n_heads=8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Forward pass\n",
    "output = model(Q, K, V, mask=tgt_mask)\n",
    "\n",
    "print(\"Attention output shape:\", output.shape)\n",
    "\n",
    "# Define the reward function (this is a simple placeholder; a real reward function should be based on the task)\n",
    "def reward_function(predicted_translation, target_translation):\n",
    "    # Compute reward as cosine similarity between predicted and target translation (simplified)\n",
    "    return torch.cosine_similarity(predicted_translation, target_translation, dim=-1).mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
